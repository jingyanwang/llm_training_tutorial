{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b0f2ce",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/tasks/language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bd91a",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "eli5 = load_dataset(\"eli5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d6cc3",
   "metadata": {},
   "source": [
    "DatasetDict({\n",
    "    train_eli5: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 272634\n",
    "    })\n",
    "    validation_eli5: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 9812\n",
    "    })\n",
    "    test_eli5: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 24512\n",
    "    })\n",
    "    train_asks: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 131778\n",
    "    })\n",
    "    validation_asks: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 2281\n",
    "    })\n",
    "    test_asks: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 4462\n",
    "    })\n",
    "    train_askh: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 98525\n",
    "    })\n",
    "    validation_askh: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 4901\n",
    "    })\n",
    "    test_askh: Dataset({\n",
    "        features: ['q_id', 'title', 'selftext', 'document', 'subreddit', 'answers', 'title_urls', 'selftext_urls', 'answers_urls'],\n",
    "        num_rows: 9764\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb3db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = load_dataset(\"eli5\", split=\"train_asks[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa299c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b4841",
   "metadata": {},
   "source": [
    "![](eli5_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee917e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9430cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95e651",
   "metadata": {},
   "source": [
    "{'q_id': '1oy5tc', 'title': 'in football whats the point of wasting the first two plays with a rush - up the middle - not regular rush plays i get those', 'selftext': '', 'document': '', 'subreddit': 'explainlikeimfive', 'answers.a_id': ['ccwtgnz', 'ccwtmho', 'ccwt946', 'ccwvj0u'], 'answers.text': [\"Keep the defense honest, get a feel for the pass rush, open up the passing game. An offense that's too one dimensional will fail. And those rushes up the middle can be busted wide open sometimes for big yardage.\", \"If you throw the ball all the time, then the defense will adapt to always cover for a pass.  By doing a simple running play every now and then, you force the defense to stay close and guard against the run.  Sometimes, the offense can catch the defense off guard by faking a run and freeing up their receivers.\\n\\nAlso, you don't have to gain massive yards on every single play.  Sometimes, it works best to gain a few yards at a time.  As long as you get the first down, you are in good shape.\", 'In most cases the O-Line is supposed to make a hole for the running back to go through. If you run too many plays to the outside/throws the defense will catch on.\\n\\nAlso, 2 5 yard plays gets you a new set of downs.', \"I you don't like those type of plays, watch CFL.  We only get 3 downs so you can't afford to waste one.  Lots more passing.\"], 'answers.score': [3, 2, 2, 2], 'title_urls.url': [], 'selftext_urls.url': [], 'answers_urls.url': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13562977",
   "metadata": {},
   "source": [
    "# load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86257714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5704fa",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=eli5[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4439e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc541b",
   "metadata": {},
   "source": [
    "![](causal_processed_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234d397",
   "metadata": {},
   "source": [
    "# load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaee92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "import torch\n",
    "\n",
    "model = model.to(torch.device('cuda:7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cecaae",
   "metadata": {},
   "source": [
    "# building the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc952f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_eli5_clm-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cdb9b",
   "metadata": {},
   "source": [
    "![](causal_data_size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390500b",
   "metadata": {},
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a9dda",
   "metadata": {},
   "source": [
    "![](causal_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca93dde7",
   "metadata": {},
   "source": [
    "# model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78621991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d49361",
   "metadata": {},
   "source": [
    "# model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182bfcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\n",
    "output_dir = 'causal_model_trained',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca532c6f",
   "metadata": {},
   "source": [
    "# model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd4b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"causal_model_trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2b4d4",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e9242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ec013",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Somatic hypermutation allows the immune system to\"\n",
    "\n",
    "generator(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488fc8aa",
   "metadata": {},
   "source": [
    "![](causal_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5583489",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
