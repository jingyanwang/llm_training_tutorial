{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767e6d2d",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/tasks/question_answering#load-squad-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deade8fd",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad41161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
    "\n",
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d2267",
   "metadata": {},
   "source": [
    ">>> squad\n",
    "Dataset({\n",
    "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
    "    num_rows: 5000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41542ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#squad = squad.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeb1b0",
   "metadata": {},
   "source": [
    ">>> squad\n",
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
    "        num_rows: 4000\n",
    "    })\n",
    "    test: Dataset({\n",
    "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
    "        num_rows: 1000\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb071a8",
   "metadata": {},
   "source": [
    "{'id': '56d34dea59d6e414001462b0', 'title': 'Frédéric_Chopin', 'context': \"At the funeral of the tenor Adolphe Nourrit in Paris in 1839, Chopin made a rare appearance at the organ, playing a transcription of Franz Schubert's lied Die Gestirne. On 26 July 1840 Chopin and Sand were present at the dress rehearsal of Berlioz's Grande symphonie funèbre et triomphale, composed to commemorate the tenth anniversary of the July Revolution. Chopin was reportedly unimpressed with the composition.\", 'question': 'Chopin attended the funeral of who in 1839?', 'answers': {'text': ['Adolphe Nourrit'], 'answer_start': [28]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c3b37",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    ##\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "            ##\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41416d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381e23d",
   "metadata": {},
   "source": [
    ">>> tokenized_squad\n",
    "DatasetDict({\n",
    "    train: Dataset({\n",
    "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
    "        num_rows: 87599\n",
    "    })\n",
    "    validation: Dataset({\n",
    "        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
    "        num_rows: 10570\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c32f5",
   "metadata": {},
   "source": [
    "# trainer building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78024ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n",
    "\n",
    "model = model.to(torch.device('cuda:7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47746c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f60320",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c183fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb24ef7",
   "metadata": {},
   "source": [
    "![](gpu7_qa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586306a",
   "metadata": {},
   "source": [
    "![](training_qa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04f679",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7919f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\n",
    "output_dir = 'qa_trained_model',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dab7b",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0873b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc11fa",
   "metadata": {},
   "source": [
    "![](qa_evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8ad52",
   "metadata": {},
   "source": [
    "# load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41766f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"qa_trained_model\")\n",
    "\n",
    "model = model.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441360c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\n",
    "    \"question-answering\", \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04450832",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e9b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many programming languages does BLOOM support?\"\n",
    "context = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1eda68",
   "metadata": {},
   "source": [
    "![](qa_example2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e31c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is my name?\"\n",
    "context = \"My name is Jimmy\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4bd769",
   "metadata": {},
   "source": [
    "![](qa_example1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533da3b",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
